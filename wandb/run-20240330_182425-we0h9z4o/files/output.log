You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Traceback (most recent call last):
  File "/zhome/ea/9/137501/Desktop/ML_health/ML_health/src/models/T5_model.py", line 91, in generate
    "prob_null": prob_null[idx].cpu().numpy().tolist(),
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 3825, in decode
    return self._decode(
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/tokenization_utils.py", line 1024, in _decode
    sub_texts.append(self.convert_tokens_to_string(current_sub_text))
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py", line 441, in convert_tokens_to_string
    if token in self.all_special_tokens:
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1352, in all_special_tokens
    all_toks = [str(s) for s in self.all_special_tokens_extended]
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1336, in all_special_tokens_extended
    for value in self.special_tokens_map_extended.values():
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 1319, in special_tokens_map_extended
    attr_value = getattr(self, "_" + attr)
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/zhome/ea/9/137501/Desktop/ML_health/ML_health/main.py", line 93, in <module>
    evaluator.save_predictions(name, pred_dict)
  File "/zhome/ea/9/137501/Desktop/ML_health/project-env/lib/python3.10/site-packages/dtu/__init__.py", line 235, in start
    cls.run(*args)
  File "/zhome/ea/9/137501/Desktop/ML_health/ML_health/main.py", line 75, in run
    else:
  File "/zhome/ea/9/137501/Desktop/ML_health/ML_health/src/models/T5_model.py", line 91, in generate
    "prob_null": prob_null[idx].cpu().numpy().tolist(),
